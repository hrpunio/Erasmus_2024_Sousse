---
title: "Statistical reproducible computing with open source tools"
author: | 
  | Tomasz Przechlewski
  | email: t.plata-przechlewski@psw.kwidzyn.edu.pl
  | affiliation: Powiślańska Szkoła Wyższa (Kwidzyn/Poland)
date: "2024"
output:
  slidy_presentation:
    theme: lumen
  ioslides_presentation: default
  beamer_presentation: default
---

## Contents

* A bit of theory

* Practical exercises

## Statistics in 3 words

data + procedures (incl. theory of statistics) + tools

## Replicability vs Reproducibility

Hot topic: google: reproducible+research = 476000 (2/6/2023)

**Replicability**: independent experiment targetting the same question
will produce a result consistent with the original study.
  
**Reproducibility**: ability to repeat
the experiment with exactly the same outcome as
originally reported

Sounds easy? But it is not. 

* To repeat the analysis one must has
access to **data** and **tools** (ie programs) and one has to know
how the analysis was performed (ie detailed description)

* Excel is not a standard

* Reports published in scientific journals lacks data and the
description is far from complete

Computational science is facing a credibility crisis: it's impossible
to verify most of the computational results presented at conferences
and in papers today. (Donoho D. et al 2009)

We can modify our 3 words definition of statistics:

## Statistics in 4 words

data + procedures (theory of statistics) + tools + description (for humans)

RR is possible if all above is available.

## Components of statistics

### Data

Messy and unreliable

Usually complicated

Not clean (needs extra effort before can be analysed)

### Procedures

usually poorly documented

### Tools

usually black-boxes

### Description

Copy-pasted from computer output

## Making statistics with a spreadsheets

store data + transform data + apply procedures + copy/paste results

Actually not a perfect statistical tool. What is missing:

* lack of build-in missing value

* many procedures are unavailable (ANOVA for example) 
  or cumbersome to use
  (chi-squared test of independence for example)

* poor accuracy/unreliable results

* Poor automation without expert knowledge. Average user does a lot 
  of manual copy-pasting and/or mouse clickig/moving

## Literate statistical programming (LSP)

LSP is based on Literate Programming (LP) concept proposed
by Donald Knuth in early 1980s:
**Program code and description in one document**. 

Statistical computing code is embedded inside descriptive text.

Literate statistical program is turned into
report by executing code and inserting the results obtained.

## LSP: Benefits/Problems/Tools

* Reliability: Easier to find/fix bugs or to avoid errors

* Efficiency: automated computing. Repetitive tasks are performed automatically

* Institutional memory. LSP documents are better for storage

Problems of LSP: Many incl. costs and learning curve

## LSP formats and tools

* Document formatting language: Rmarkdown (variant of Markdown)

* Statistical programming language: **R**

* Tool to transform Rmd + R computantion output into complete report: **pandoc**

A file **format** is a standard way that information is encoded for storage 
in a computer file.


## There is a life without speadsheet too: R and Rstudio

R is both *programming language*  for statistical computing and graphics and 
a software (ie application) to execute programs written in R.

There is a computer program called R (R.exe
in MS Windows which can execute R programs (often called scripts.)

So to compute something one has to write a script using R syntax,
and then run this script with R.

Rstudio is an *environment* through which to use R. In Rstudio one can simultaneously write code, execute
code it, manage data, get help, view plots. Rstudio is a commercial product distributed
under dual-license system by RStudio, Inc. Key developer of RStudio is Hadley Wickham 
a brilliant New Zealander (cf [Hadley Wickham](https://en.wikipedia.org/wiki/Hadley_Wickham) )

At the touch of a button, RStudio runs R and Pandoc in the background, making ones work much easier

## Markdown and R-markdown

Markdown is a lightweight (ie. simple) **markup language** for creating formatted text using a plain-text editor.

```
## Markdown

Markdown is a lightweight (ie. simple) **markup language** for creating formatted
text using a plain-text editor.
```

R-markdown is an extension of markdown in which one can embed R code
fragments

## Programming is difficult

True, but we are talking about scripting ie. easy programming

Programming in spreadsheet is difficult too




Programing sounds scary, but you don't to be a programmer to use R.

## R vs Excel

**Difference**:

R: data invisible, program (how the data is processed) visible;
in Excell the other ways round

The bigger the dataset the more cumbersome an Excel-aproach is (IMO)

**Moreover data + functions is not the whole story**

**Meaningful data analasis: data + functions + description**

without *description* it is difficult to understand the details and
results of analysis, so:


Excel: data + functions + description

**Problem**: all is intermixed

R: separates data/functions/descriptions

Conclusion: with R data analysis is meaningful and easier

## Learning resources and data banks

**Learnig resources**

* [Rstudio](https://www.rstudio.com/resources/cheatsheets/)

* [Making Data Meaningful](https://www.unece.org/stats/documents/writing/)

* [bookdown: Authoring Books and Technical Documents with R Markdown](https://bookdown.org/yihui/bookdown/)

**Data banks**

* [Polish Main Statistical Office](https://stat.gov.pl/)

* [Bank Danych Lokalnych (Local Data Bank)]()https://bdl.stat.gov.pl/BDL/start)

* [Eurostat (European Union Statistical Office)](https://ec.europa.eu/eurostat/data/database)

* [My github repository](https://github.com/hrpunio))










